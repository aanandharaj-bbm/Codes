{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark.sql.functions as func\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import subprocess\n",
    "sql = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = !gsutil ls gs://ds-taste-dfp/raw_click_data/aug/\n",
    "dat_iab= sql.read.parquet(\"gs://ds-taste-dfp/raw_iab_data/31-10-2017/result_dfp/*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-02.tar.gz\n"
     ]
    }
   ],
   "source": [
    "for sub_file in files:\n",
    "    sub_str = sub_file.split(\"/\")[5]\n",
    "    date = sub_str[:10]   \n",
    "    print sub_str\n",
    "    if sub_str[-3:] == 'tgz':\n",
    "        gcs_input_path = \"gs://ds-taste-dfp/raw_click_data/aug/\"+sub_str\n",
    "        subprocess.call([\"gsutil\",\"-m\",\"cp\",\"-r\" ,gcs_input_path,\".\"])\n",
    "        subprocess.call([\"tar\",\"zxvf\",sub_str])\n",
    "        gcs_output_path = \"gs://ds-url-catag/\"+ date + \"/\"\n",
    "        subprocess.call([\"gsutil\",\"cp\",\"-r\",\"home\" ,gcs_output_path])\n",
    "        subprocess.call([\"rm\",\"-rf\",\"home\"])\n",
    "        subprocess.call([\"rm\",\"-rf\",sub_str])\n",
    "        \n",
    "        #reading click data \n",
    "        path = \"gs://ds-taste-dfp/raw_click_data/unzipped/\"+ date + \"/home/tastegraph_app/ds/adhoc/dfp/data/\" + date + \"/\"\n",
    "        clicks_rdd = sc.textFile(path,use_unicode=False).repartition(sc.defaultParallelism * 3)\n",
    "        data_clicks = clicks_rdd.map(lambda x: x.split('\\t')).filter(lambda line: len(line)== 4).map(lambda y: (y[0],y[1],y[2],y[3])).toDF(['type','orderid','line_itemid','rdid'])\n",
    "        \n",
    "        #processing click data\n",
    "        data_clicks= data_clicks.withColumn('Impressions',when(col('type') == 'SERVE',1).otherwise(0))\n",
    "        data_clicks = data_clicks.withColumn('Clicks',when(col('type') == 'OFFER',1).otherwise(0))\n",
    "        data_clicks = data_clicks.withColumn('rdid',when(col('rdid') == '',None).otherwise(col('rdid')))\n",
    "        data_clicks_aggre_one = data_clicks.groupby('orderid','line_itemid','rdid').agg(func.sum(\"Impressions\").alias('impressions'),func.sum(\"Clicks\").alias('clicks'))\n",
    "        dfp_click_iab = data_clicks_aggre_one.join(dat_iab,(dat_iab.order_id == data_clicks_aggre_one.orderid) & (dat_iab.lineitemid == data_clicks_aggre_one.line_itemid),'left' ).select([(xx) for xx in data_clicks_aggre_one.columns]+[dat_iab.IABTier1Categorization])\n",
    "        \n",
    "        #writing to parquet file\n",
    "        parquet_path='gs://ds-taste-dfp/aggregated_data/click_aggregated_by_date/August/'+ date +'.parquet'\n",
    "        dfp_click_iab.dropDuplicates().write.parquet(parquet_path)\n",
    "    \n",
    "    elif sub_str[-6:] == 'tar.gz':\n",
    "        path = \"gs://ds-taste-dfp/raw_click_data/aug/\"+sub_str\n",
    "        clicks_rdd = sc.textFile(path,use_unicode=False).repartition(sc.defaultParallelism * 3)\n",
    "        data_clicks = clicks_rdd.map(lambda x: x.split('\\t')).filter(lambda line: len(line)== 4).map(lambda y: (y[0],y[1],y[2],y[3])).toDF(['type','orderid','line_itemid','rdid'])\n",
    "        \n",
    "        #processing click data\n",
    "        data_clicks= data_clicks.withColumn('Impressions',when(col('type') == 'SERVE',1).otherwise(0))\n",
    "        data_clicks = data_clicks.withColumn('Clicks',when(col('type') == 'OFFER',1).otherwise(0))\n",
    "        data_clicks = data_clicks.withColumn('rdid',when(col('rdid') == '',None).otherwise(col('rdid')))        \n",
    "        data_clicks_aggre_one = data_clicks.groupby('orderid','line_itemid','rdid').agg(func.sum(\"Impressions\").alias('impressions'),func.sum(\"Clicks\").alias('clicks'))\n",
    "        dfp_click_iab = data_clicks_aggre_one.join(dat_iab,(dat_iab.order_id == data_clicks_aggre_one.orderid) & (dat_iab.lineitemid == data_clicks_aggre_one.line_itemid),'left' ).select([(xx) for xx in data_clicks_aggre_one.columns]+[dat_iab.IABTier1Categorization])\n",
    "\n",
    "        \n",
    "        #writing to parquet file\n",
    "        parquet_path='gs://ds-taste-dfp/aggregated_data/click_aggregated_by_date/August/'+ date +'.parquet'\n",
    "        dfp_click_iab.dropDuplicates().write.parquet(parquet_path)\n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
