{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.functions import *\n",
    "sc.stop()\n",
    "from pyspark.sql import SQLContext\n",
    "sc =SparkContext()\n",
    "sqlContext = SQLContext(sc)\n",
    "import pyspark.sql.functions as func\n",
    "import sys\n",
    "from pyspark.sql.functions import countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in data again\n",
    "df_new = sqlContext.read.parquet(\"gs://ds-sean-scrapy/dataflow-analisis-production/plenty/events/product=bbm/product=bbm/aggregated/new/transposed/BBM-STICKER-SEND/\")\n",
    "df_demo = sqlContext.read.parquet(\"gs://ds-user-demographic/parquet/tastes_mau_1024.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "active_base  = df_new.alias('a').join(df_demo.alias('b'),col('b.regid') == col('a.user_id_n')).select([col('time'),col('City'),col('Connection'),col('Country'),col('Device_Brand'),col('Device_Model'),col('New_User'),col('OS_Version'),col('app_name'),col('carrier'),col('license_type'),col('a.platform'),col('sticker_id'),col('sticker_pack_id'),col('user_id_n')]+[col('language'),col('age_group'),col('gender')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of days logged in\n",
    "active_base = active_base.withColumn('date', concat(df_new.time.substr(1, 10)))\n",
    "active_base = active_base.withColumn('month', concat(df_new.time.substr(4, 5)))\n",
    "distinctdate = active_base.groupby('user_id_n').agg(countDistinct('date').alias('numofdays'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distinctdate.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consecutive days computation\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "new_base = active_base.groupby(\"user_id_n\").agg(F.collect_list(\"date\").alias(\"date_list\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType,StringType\n",
    "from datetime import datetime,timedelta\n",
    "#function to derive average consecutive days\n",
    "def con_days(raw):\n",
    "    raw = list(set(raw))\n",
    "    n = len(raw)\n",
    "    raw = sorted(raw, key=lambda d: map(int, d.split('-')))\n",
    "    no_of_days = 0\n",
    "    no_of_groups = 0\n",
    "    group = 0\n",
    "    total_days = 0\n",
    "    res = []\n",
    "    for i in range(0,n-1):\n",
    "        current_date = datetime.strptime(raw[i], \"%Y-%m-%d\")\n",
    "        current_date_mod = datetime.strftime(current_date, \"%Y-%m-%d\")\n",
    "        con_date = current_date + timedelta(days=1)\n",
    "        con_date_mod = datetime.strftime(con_date, \"%Y-%m-%d\")\n",
    "\n",
    "        next_date = datetime.strptime(raw[i+1], \"%Y-%m-%d\")\n",
    "        next_date_mod = datetime.strftime(next_date, \"%Y-%m-%d\")\n",
    "        if con_date_mod == next_date_mod :\n",
    "            no_of_days += 1\n",
    "            total_days += 1\n",
    "            if no_of_days == 1:\n",
    "                group += 1\n",
    "                no_of_groups = group\n",
    "\n",
    "        else:\n",
    "            no_of_days = 0\n",
    "    res.append(total_days)\n",
    "    return total_days\n",
    "\n",
    "consecutive_days = udf(con_days,StringType())\n",
    "\n",
    "def con_groups(raw):\n",
    "    raw = list(set(raw))\n",
    "    n = len(raw)\n",
    "    raw = sorted(raw, key=lambda d: map(int, d.split('-')))\n",
    "    no_of_days = 0\n",
    "    no_of_groups = 0\n",
    "    group = 0\n",
    "    total_days = 0\n",
    "    res = []\n",
    "    for i in range(0,n-1):\n",
    "        current_date = datetime.strptime(raw[i], \"%Y-%m-%d\")\n",
    "        current_date_mod = datetime.strftime(current_date, \"%Y-%m-%d\")\n",
    "        con_date = current_date + timedelta(days=1)\n",
    "        con_date_mod = datetime.strftime(con_date, \"%Y-%m-%d\")\n",
    "\n",
    "        next_date = datetime.strptime(raw[i+1], \"%Y-%m-%d\")\n",
    "        next_date_mod = datetime.strftime(next_date, \"%Y-%m-%d\")\n",
    "        if con_date_mod == next_date_mod :\n",
    "            no_of_days += 1\n",
    "            total_days += 1\n",
    "            if no_of_days == 1:\n",
    "                group += 1\n",
    "                no_of_groups = group\n",
    "\n",
    "        else:\n",
    "            no_of_days = 0\n",
    "    return no_of_groups\n",
    "\n",
    "groups = udf(con_groups,StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_base = new_base.withColumn(\"Consective_days\",consecutive_days('date_list'))\n",
    "new_base = new_base.withColumn(\"Consective_groups\",groups('date_list'))\n",
    "new_base = new_base.withColumn(\"avg_con_days\",when((col('Consective_days') != 0)  & (col('Consective_groups') != 0) , round((col('Consective_days')/col('Consective_groups')))).otherwise(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_base.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sticker packs sent\n",
    "stickers_sent = active_base.select('user_id_n','sticker_pack_id').groupby('user_id_n').agg(count('sticker_pack_id').alias('sticker_packs_sent'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distinct sticker packs sent \n",
    "stickers_distinct_sent = active_base.select('user_id_n','sticker_pack_id').groupby('user_id_n').agg(countDistinct('sticker_pack_id').alias('distinct_sticker_packs_sent'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stickers_distinct_sent.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rocessing sticker type data\n",
    "# from pyspark.sql.types import StringType\n",
    "# import re\n",
    "# sticker_types = sc.textFile(\"gs://ds-url-catag/stick_bytype/all_stickers/*\") \\\n",
    "#     .map(lambda line: line.split(\",\")).map(lambda line: (line[0],line[1])).toDF(['id','type'])\n",
    "# remove_quotes = udf(lambda x: re.sub('\"','',x), StringType())\n",
    "# remove_slashes = udf(lambda x: re.sub('\\\\\\\\','',x), StringType())\n",
    "# new_df = sticker_types.select(*[remove_quotes(column).alias(column) for column in sticker_types.columns])\n",
    "# new_df =  new_df.select(*[remove_slashes(column).alias(column) for column in new_df.columns])\n",
    "# new_df.dropDuplicates().write.mode('overwrite').parquet(\"gs://ds-url-catag/stick_bytype/agg_proc_stickertypes/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in sticker type data\n",
    "Final_stickers_types = sqlContext.read.parquet(\"gs://ds-url-catag/stick_bytype/agg_proc_stickertypes/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final_stickers_types.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sticker types used by users\n",
    "data_join = active_base.join(Final_stickers_types,Final_stickers_types.id== active_base.sticker_pack_id).select([active_base.sticker_pack_id,active_base.user_id_n]+[Final_stickers_types.id,Final_stickers_types.type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------------+\n",
      "|        type|count(DISTINCT user_id_n)|\n",
      "+------------+-------------------------+\n",
      "|        FREE|                  7463849|\n",
      "|SUBSCRIPTION|                      257|\n",
      "|        PAID|                    24766|\n",
      "|DISCONTINUED|                   206008|\n",
      "+------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_join.groupby('type').agg(countDistinct('user_id_n')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deriving sticker type variables\n",
    "#paid\n",
    "data_join  = data_join.withColumn(\"is_paid\",when(col('type') == 'PAID',data_join.sticker_pack_id).otherwise(None))\n",
    "data_join  = data_join.withColumn(\"is_free\",when(col('type') == 'FREE',data_join.sticker_pack_id).otherwise(None))\n",
    "data_join  = data_join.withColumn(\"is_subscribed\",when(col('type') == 'SUBSCRIPTION',data_join.sticker_pack_id).otherwise(None))\n",
    "data_join  = data_join.withColumn(\"is_discontinued\",when(col('type') == 'DISCONTINUED',data_join.sticker_pack_id).otherwise(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sticker_types_aggre = data_join.groupby('user_id_n','is_paid','is_free','is_subscribed','is_discontinued').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing strings with numbers for clustering\n",
    "sticker_types_aggre = sticker_types_aggre.withColumn('is_paid',when(col('is_paid').isNull(),0).otherwise(1))\n",
    "sticker_types_aggre = sticker_types_aggre.withColumn('is_free',when(col('is_free').isNull(),0).otherwise(1))\n",
    "sticker_types_aggre = sticker_types_aggre.withColumn('is_subscribed',when(col('is_subscribed').isNull(),0).otherwise(1))\n",
    "sticker_types_aggre = sticker_types_aggre.withColumn('is_discontinued',when(col('is_discontinued').isNull(),0).otherwise(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_stick_base = sticker_types_aggre.groupBy('user_id_n').agg(func.sum('is_paid').alias('sum_paid'),func.sum('is_free').alias('sum_free'),func.sum('is_subscribed').alias('sum_subs'),func.sum('is_discontinued').alias('sum_discont'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join all datasets\n",
    "data_one = distinctdate.join(new_base,new_base.user_id_n == distinctdate.user_id_n).select([distinctdate.user_id_n,distinctdate.numofdays]+[new_base.avg_con_days])\n",
    "data_two = data_one.join(stickers_sent,stickers_sent.user_id_n == data_one.user_id_n).select([data_one.user_id_n,data_one.numofdays,data_one.avg_con_days]+[stickers_sent.sticker_packs_sent])\n",
    "data_three = data_two.join(stickers_distinct_sent,stickers_distinct_sent.user_id_n == data_two.user_id_n).select([data_two.user_id_n,data_two.numofdays,data_two.avg_con_days,data_two.sticker_packs_sent]+[stickers_distinct_sent.distinct_sticker_packs_sent])\n",
    "data_four = data_three.join(more_stick_base,more_stick_base.user_id_n == data_three.user_id_n).select([data_three.user_id_n,data_three.numofdays,data_three.avg_con_days,data_three.sticker_packs_sent,data_three.distinct_sticker_packs_sent]+[more_stick_base.sum_paid,more_stick_base.sum_free,more_stick_base.sum_subs,more_stick_base.sum_discont])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the final file to all the data \n",
    "data_four.dropDuplicates().write.mode('overwrite').parquet(\"gs://ds-url-catag/stick_statistics/derived_features/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
