{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql.functions import countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in data agains\n",
    "dfp_click_data = spark.read.parquet(\"gs://ds-taste-dfp/aggregated_data/click_aggregated_by_date/year=*/*/*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate all the impression and clicks by campaigns and userid \n",
    "dfp_click_data_agree = dfp_click_data.groupby('orderid','line_itemid','adid','IABTier1Categorization').agg(func.sum(\"impressions\").alias('Impressions'),func.sum(\"clicks\").alias('Clicks'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_travel = dfp_click_data_agree.where((col('orderid') == '2205238061') | (col('orderid') == '2204480300') | (col('orderid') == '2196314095') | (col('orderid') == '2197861368') | (col('orderid') == '2250263757') | (col('orderid') == '2256707010') | (col('orderid') == '2260774529') | (col('orderid') == '2266410121')  | (col('orderid') == '2250360384')  | (col('orderid') == '2256702195')  | (col('orderid') == '2260790765')    | (col('orderid') == '2266260188'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_shopping = dfp_click_data_agree.where((col('orderid') == '2180152030') | (col('orderid') == '2204480300'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orders_travel.groupby('orderid').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orders_shopping.groupby('orderid').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples where atleast there is one click and removing null adids \n",
    "sample = orders_travel.where(col('Clicks') > 0 )\n",
    "new_sample = sample.where(col('adid') != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples where atleast there is one click and removing null adids \n",
    "sample_shopping = orders_shopping.where(col('Clicks') > 0 )\n",
    "new_sample_shopping = sample_shopping.where(col('adid') != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_shopping.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_sample_shopping.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "import binascii\n",
    "from pyspark.sql.types import StringType\n",
    "import re\n",
    "\n",
    "SALT_A = \"77EfzyR%iZtyTFAK7lyZ_X=B7e^b1atUx%W+Rx0A3ja~b5yjGL-q==po%nkL\"\n",
    "\n",
    "def adid_to_ppid(adid):\n",
    "    sha1hash = []\n",
    "    pattern = re.compile(\"^[a-zA-Z0-9\\-]{8}-[a-zA-z0-9]{4}-[a-zA-z0-9]{4}-[a-zA-z0-9]{4}-[a-zA-z0-9]{12}\")\n",
    "    if re.match(pattern,adid) is not None:\n",
    "        text = adid + SALT_A\n",
    "        sha1_dig = sha1(text).digest()\n",
    "        sha1hash = [ord(c) for c in sha1_dig]\n",
    "    return binascii.hexlify(bytearray(sha1hash))\n",
    "\n",
    "adid_ppid_udf = udf(adid_to_ppid, StringType())\n",
    "\n",
    "\n",
    "new_sample = new_sample.withColumn('ppid',adid_ppid_udf('adid'))\n",
    "new_sample_shopping = new_sample_shopping.withColumn('ppid',adid_ppid_udf('adid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample.select('ppid').distinct().coalesce(1).write.mode('overwrite').format(\"com.databricks.spark.csv\").save(\"gs://ds-url-catag/mark_request/mar20/travel_ppids/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample_shopping.select('ppid').distinct().coalesce(1).write.mode('overwrite').format(\"com.databricks.spark.csv\").save(\"gs://ds-url-catag/mark_request/mar20/shopping_ppid/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample_shopping.select('adid').distinct().coalesce(1).write.mode('overwrite').format(\"com.databricks.spark.csv\").save(\"gs://ds-url-catag/mark_request/mar20/shopping_adid/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
