{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repartition_data(year,month_dict,data_source):\n",
    "    #read,process all of the click data\n",
    "    for y in year:\n",
    "        for m in xrange(3,4):\n",
    "            for d in xrange(30,32):\n",
    "                for key,value in  month_dict.iteritems():\n",
    "                    if key == m:\n",
    "                        month_name = value \n",
    "                date = str(y)+'-'+str(m)+'-'+str(d)\n",
    "                print date\n",
    "                try:\n",
    "                    new_data_path = sqlContext.read.parquet(\"gs://ds-url-catag/plenty_stickers_data/\"+data_source+\"/repartioned_data/\"+str(y)+'/'+month_name+'/'+date+'.parquet')\n",
    "                except Exception,e:\n",
    "                    path = 'gs://ds-url-catag/plenty_stickers_data/'+data_source+'/year='+str(y)+'/month='+str(m)+'/day='+str(d)+'/*'\n",
    "                    print path\n",
    "                    try:\n",
    "                        original_file = spark.read.parquet(path)\n",
    "                        status =  \"File exists\"\n",
    "                    except Exception,e:\n",
    "                        status =  \"Nope\"\n",
    "                    if status == \"File exists\":\n",
    "                        print status\n",
    "                        new_file = original_file.repartition(1)\n",
    "                        write_path = \"gs://ds-url-catag/plenty_stickers_data/\"+data_source+\"/repartioned_data/\"+str(y)+'/'+month_name+'/'+date+'.parquet'\n",
    "                        print write_path\n",
    "                        new_file.dropDuplicates().write.mode('overwrite').parquet(write_path)\n",
    "    return \"Completed\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    Sticker_datasources = ['event=BBM-STICKER-RECEIVED']\n",
    "    # values for Sticker_Datasources\n",
    "    # 'event=BBM-STICKER-RECEIVED','event=BBM-STICKER_SPONSORED_LINK-CLICK','event=BBM-STICKER-CLICK','event=BBM-STICKER-DOWNLOAD','event=BBM-STICKER-SEND'\n",
    "    year= [2018]\n",
    "    month_dict = {1: \"January\",2: \"February\",3 : \"march\",4 :\"April\",5 :\"May\",6:\"June\",7:\"July\",8:\"August\",9:\"September\",10:\"October\",11:\"November\",12:\"December\"}\n",
    "    for ds in Sticker_datasources:\n",
    "         repartition_data(year,month_dict,ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
