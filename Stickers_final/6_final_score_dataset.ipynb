{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "Sticker_datasources = ['event=BBM-STICKER-RECEIVED','event=BBM-STICKER_SPONSORED_LINK-CLICK','event=BBM-STICKER-CLICK','event=BBM-STICKER-DOWNLOAD','event=BBM-STICKER-SEND']\n",
    "for ds in Sticker_datasources:\n",
    "    #reading in sticker type data\n",
    "    feature_data = spark.read.parquet(\"gs://ds-url-catag/plenty_stickers_data/\"+ds+\"/derived_features/Final/\")\n",
    "    main_data = feature_data\n",
    "    for cn in main_data.columns:\n",
    "        #if users can pay or not\n",
    "        if \"sum_paid\" in cn:\n",
    "            main_data = main_data.withColumn(\"Can_Pay\",when(main_data[cn] !=0 ,\"yes\").otherwise(\"No\"))\n",
    "            #Ability to pay for users\n",
    "            # calculate average sticker pack download to distinguish the clusters \n",
    "            #categorize ability to pay\n",
    "        if \"sticker_packs\" in cn:\n",
    "            main_data = main_data.withColumn('Abilty_to_pay',when(main_data[cn] >= 43.0,'Very High') \\\n",
    "                                             .otherwise(when((main_data[cn] >= 7.00) & (main_data[cn] < 43.0),'High') \\\n",
    "                                             .otherwise(when((main_data[cn] > 3.0) & (main_data[cn] < 7.0),'Medium') \\\n",
    "                                             .otherwise(when((main_data[cn] > 1.4) & (main_data[cn] < 3.0),'low') \\\n",
    "                                             .otherwise('very low')))))\n",
    "        #get the percentiles for free,paid and subscribed among the clusters\n",
    "        #usage rate of free,paid and subscribed\n",
    "        if \"distinct\" in cn:\n",
    "            distinct_column_name = cn\n",
    "        if \"sum_free\" in cn:\n",
    "            main_data = main_data.withColumn('Freestickerusagerate',main_data[cn]/main_data[distinct_column_name])\n",
    "        if \"sum_paid\" in cn:\n",
    "            main_data = main_data.withColumn('paidstickerusagerate',main_data[cn]/main_data[distinct_column_name])\n",
    "        if \"sum_subs\" in cn:\n",
    "            main_data = main_data.withColumn('subsstickerusagerate',main_data[cn]/main_data[distinct_column_name])\n",
    "\n",
    "    from pyspark.sql import Window\n",
    "    #Categorizing the usage rates \n",
    "    # #calculate the top percent rank for users performing better in the same cluster \n",
    "    window_freerank = Window.partitionBy('Abilty_to_pay').orderBy(main_data['Freestickerusagerate'].desc())\n",
    "    main_data = main_data.withColumn('Free_Stickers_rank',percent_rank().over(window_freerank).alias('rank'))\n",
    "\n",
    "    window_paidrank = Window.partitionBy('Abilty_to_pay').orderBy(main_data['paidstickerusagerate'].desc())\n",
    "    main_data = main_data.withColumn('Paid_Stickers_rank',percent_rank().over(window_freerank).alias('rank'))\n",
    "\n",
    "    window_subsrank = Window.partitionBy('Abilty_to_pay').orderBy(main_data['subsstickerusagerate'].desc())\n",
    "    main_data = main_data.withColumn('Subscribed_Stickers_rank',percent_rank().over(window_freerank).alias('rank'))\n",
    "\n",
    "    #assign low,medium and high values\n",
    "    main_data = main_data.withColumn('Free_sticker_usage',when(col('Free_Stickers_rank') <= 0.2,'High').otherwise(when( (col('Free_Stickers_rank') > 0.2) & (col('Free_Stickers_rank') < 0.5),'medium').otherwise('low')))\n",
    "    main_data = main_data.withColumn('paid_sticker_usage',when(col('Paid_Stickers_rank') <= 0.2,'High').otherwise(when( (col('Paid_Stickers_rank') > 0.2) & (col('Paid_Stickers_rank') < 0.5),'medium').otherwise('low')))\n",
    "    main_data = main_data.withColumn('Subscribed_sticker_usage',when(col('Subscribed_Stickers_rank') <= 0.2,'High').otherwise(when( (col('Subscribed_Stickers_rank') > 0.2) & (col('Subscribed_Stickers_rank') < 0.5),'medium').otherwise('low')))\n",
    "\n",
    "\n",
    "    main_data = main_data.withColumn('paid_sticker_usage',when(col('Can_Pay') == \"No\",\"NA\").otherwise(col('paid_sticker_usage')))\n",
    "    main_data = main_data.withColumn('Abilty_to_pay',when(col('Can_Pay') == \"No\",\"NA\").otherwise(col('Abilty_to_pay')))\n",
    "    print ds\n",
    "    main_data.select('user_id_n','Can_Pay','Abilty_to_pay','Free_sticker_usage','paid_sticker_usage').write.mode('overwrite').parquet(\"gs://ds-url-catag/plenty_stickers_data/\"+ds+\"/pre_final_ds/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
