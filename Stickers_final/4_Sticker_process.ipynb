{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SQLContext\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_source):\n",
    "    #read the re-partitioned file \n",
    "    read_data = spark.read.parquet(\"gs://ds-url-catag/plenty_stickers_data/\"+data_source+\"/repartioned_data/*/*/*/*.parquet\")\n",
    "    #dropduplicates\n",
    "    read_data = read_data.dropDuplicates()\n",
    "    return read_data\n",
    "\n",
    "def extract_columns(dataframe,data_source):\n",
    "    #function to split a single column to multiple columns\n",
    "    def extract_json(line, schema_names):\n",
    "        result = [x for i,x in enumerate(line) if i!=4]\n",
    "        properties = json.loads(line[4])\n",
    "        flattened = []     \n",
    "        for key in schema_names:\n",
    "            if key in properties:\n",
    "                if type(properties[key]) == unicode :\n",
    "                    flattened.append(properties[key].encode('utf-8'))\n",
    "                else:\n",
    "                    flattened.append(str(properties[key]))         \n",
    "            else:\n",
    "                flattened.append(\"NULL\")\n",
    "        result = list(result) + flattened\n",
    "        return result\n",
    "    json_schema_send = spark.read.json(dataframe.rdd.map(lambda row: row.properties)).schema\n",
    "    #creating the new columns for the file \n",
    "    old_column_names_send = dataframe.drop('properties').columns\n",
    "    new_items_send = ['user_id_n' if x == 'user_id' else 'app_version_n' if  x == 'app_version' else 'city_n' if  x == 'city' else 'connection_n' if  x == 'connection' else 'country_n' if  x == 'country' else 'device_brand_n' if  x == 'device_brand' else 'device_model_n' if  x == 'device_model' else 'has_nfc_n' if  x == 'has_nfc' else 'height_resolution_n' if  x == 'height_resolution' else 'new_user_n' if  x == 'new_user' else 'new_user_n_1' if  x == 'new_User' else 'os_version_n' if  x == 'os_version' else 'width_resolution_n' if  x == 'width_resolution' else x for x in json_schema_send.names]\n",
    "    fin_col_names_send = old_column_names_send + new_items_send\n",
    "    df = dataframe.rdd.map(lambda x: extract_json(x, json_schema_send.names)).toDF(fin_col_names_send)\n",
    "    df = df.withColumn('City',when(df.City == 'NULL' ,df.city_n).otherwise(df.City))\n",
    "    df = df.drop('city_n')\n",
    "    df = df.dropDuplicates()\n",
    "    df = df.repartition(200)\n",
    "    print \"writing to files\"\n",
    "    #write to new files after processing for BBM-Sticker-Send\n",
    "    if data_source == 'event=BBM-STICKER-DOWNLOAD':\n",
    "        df.select('id',\n",
    "         'visit_id',\n",
    "         'time',\n",
    "         'City',\n",
    "         'sticker_pack_id',\n",
    "         'user_id_n').dropDuplicates().write.mode('overwrite').parquet(\"gs://ds-url-catag/plenty_stickers_data/\"+data_source+\"/aggregate_data/\")\n",
    "    else:\n",
    "        df.select('id',\n",
    "         'visit_id',\n",
    "         'time',\n",
    "         'City',\n",
    "         'sticker_id',\n",
    "         'sticker_pack_id',\n",
    "         'user_id_n').dropDuplicates().write.mode('overwrite').parquet(\"gs://ds-url-catag/plenty_stickers_data/\"+data_source+\"/aggregate_data/\")\n",
    "    return \"data written\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    Sticker_datasources = ['event=BBM-STICKER-DOWNLOAD']\n",
    "    #values for data sources\n",
    "    #'event=BBM-STICKER-RECEIVED','event=BBM-STICKER_SPONSORED_LINK-CLICK','event=BBM-STICKER-CLICK','event=BBM-STICKER-DOWNLOAD','event=BBM-STICKER-SEND'\n",
    "    for ds in Sticker_datasources:\n",
    "        dataframe  = read_data(ds)\n",
    "        extract_columns(dataframe,ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
