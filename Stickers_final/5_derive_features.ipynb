{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql.functions import countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in data again\n",
    "df_new = spark.read.parquet(\"gs://ds-url-catag/plenty_stickers_data/event=BBM-STICKER-DOWNLOAD/aggregate_data/\")\n",
    "df_demo = spark.read.parquet(\"gs://ds-user-demographic/parquet/tastes_mau_1024.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "u\"cannot resolve '`sticker_id`' given input columns: [Width_Resolution, action, platform, time, pin, ecoid, eco_id, Height_Resolution, app_name, gender, language, country_code, Device_Model, user_id_n, platform, license_type, City, bbm_version, App_Version, age_group, adid, user_id, visit_id, New_User, Device_Brand, sticker_pack_id, id, Country, OS_Version, Has_NFC, regid, carrier, Connection, name, event_action];;\\n'Project [time#4, City#6, Connection#7, Country#8, Device_Brand#9, Device_Model#10, New_User#13, OS_Version#14, app_name#17, carrier#18, license_type#21, platform#22, 'sticker_id, sticker_pack_id#23, user_id_n#24, language#57, age_group#55, gender#56]\\n+- Join Inner, (regid#54 = user_id_n#24)\\n   :- SubqueryAlias a\\n   :  +- Relation[id#0,visit_id#1,user_id#2,name#3,time#4,App_Version#5,City#6,Connection#7,Country#8,Device_Brand#9,Device_Model#10,Has_NFC#11,Height_Resolution#12,New_User#13,OS_Version#14,Width_Resolution#15,action#16,app_name#17,carrier#18,eco_id#19,event_action#20,license_type#21,platform#22,sticker_pack_id#23,user_id_n#24] parquet\\n   +- SubqueryAlias b\\n      +- Relation[ecoid#51,pin#52,adid#53,regid#54,age_group#55,gender#56,language#57,bbm_version#58,platform#59,country_code#60] parquet\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-34c4a8cd984a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mactive_base\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdf_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_demo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b.regid'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a.user_id_n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'City'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Connection'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Country'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Device_Brand'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Device_Model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'New_User'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OS_Version'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'app_name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'carrier'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'license_type'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a.platform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sticker_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sticker_pack_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user_id_n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'language'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'age_group'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gender'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.pyc\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \"\"\"\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: u\"cannot resolve '`sticker_id`' given input columns: [Width_Resolution, action, platform, time, pin, ecoid, eco_id, Height_Resolution, app_name, gender, language, country_code, Device_Model, user_id_n, platform, license_type, City, bbm_version, App_Version, age_group, adid, user_id, visit_id, New_User, Device_Brand, sticker_pack_id, id, Country, OS_Version, Has_NFC, regid, carrier, Connection, name, event_action];;\\n'Project [time#4, City#6, Connection#7, Country#8, Device_Brand#9, Device_Model#10, New_User#13, OS_Version#14, app_name#17, carrier#18, license_type#21, platform#22, 'sticker_id, sticker_pack_id#23, user_id_n#24, language#57, age_group#55, gender#56]\\n+- Join Inner, (regid#54 = user_id_n#24)\\n   :- SubqueryAlias a\\n   :  +- Relation[id#0,visit_id#1,user_id#2,name#3,time#4,App_Version#5,City#6,Connection#7,Country#8,Device_Brand#9,Device_Model#10,Has_NFC#11,Height_Resolution#12,New_User#13,OS_Version#14,Width_Resolution#15,action#16,app_name#17,carrier#18,eco_id#19,event_action#20,license_type#21,platform#22,sticker_pack_id#23,user_id_n#24] parquet\\n   +- SubqueryAlias b\\n      +- Relation[ecoid#51,pin#52,adid#53,regid#54,age_group#55,gender#56,language#57,bbm_version#58,platform#59,country_code#60] parquet\\n\""
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "active_base  = df_new.alias('a').join(df_demo.alias('b'),col('b.regid') == col('a.user_id_n')).select([col('time'),col('City'),col('Connection'),col('Country'),col('Device_Brand'),col('Device_Model'),col('New_User'),col('OS_Version'),col('app_name'),col('carrier'),col('license_type'),col('a.platform'),col('sticker_id'),col('sticker_pack_id'),col('user_id_n')]+[col('language'),col('age_group'),col('gender')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of days logged in\n",
    "active_base = active_base.withColumn('date', concat(df_new.time.substr(1, 10)))\n",
    "active_base = active_base.withColumn('month', concat(df_new.time.substr(4, 5)))\n",
    "distinctdate = active_base.groupby('user_id_n').agg(countDistinct('date').alias('numofdays'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consecutive days computation\n",
    "from pyspark.sql import functions as F\n",
    "new_base = active_base.groupby(\"user_id_n\").agg(F.collect_list(\"date\").alias(\"date_list\"))\n",
    "\n",
    "from pyspark.sql.types import FloatType,StringType\n",
    "from datetime import datetime,timedelta\n",
    "#function to derive average consecutive days\n",
    "def con_days(raw):\n",
    "    raw = list(set(raw))\n",
    "    n = len(raw)\n",
    "    raw = sorted(raw, key=lambda d: map(int, d.split('-')))\n",
    "    no_of_days = 0\n",
    "    no_of_groups = 0\n",
    "    group = 0\n",
    "    total_days = 0\n",
    "    res = []\n",
    "    for i in range(0,n-1):\n",
    "        current_date = datetime.strptime(raw[i], \"%Y-%m-%d\")\n",
    "        current_date_mod = datetime.strftime(current_date, \"%Y-%m-%d\")\n",
    "        con_date = current_date + timedelta(days=1)\n",
    "        con_date_mod = datetime.strftime(con_date, \"%Y-%m-%d\")\n",
    "\n",
    "        next_date = datetime.strptime(raw[i+1], \"%Y-%m-%d\")\n",
    "        next_date_mod = datetime.strftime(next_date, \"%Y-%m-%d\")\n",
    "        if con_date_mod == next_date_mod :\n",
    "            no_of_days += 1\n",
    "            total_days += 1\n",
    "            if no_of_days == 1:\n",
    "                group += 1\n",
    "                no_of_groups = group\n",
    "\n",
    "        else:\n",
    "            no_of_days = 0\n",
    "    res.append(total_days)\n",
    "    return total_days\n",
    "\n",
    "consecutive_days = udf(con_days,StringType())\n",
    "\n",
    "def con_groups(raw):\n",
    "    raw = list(set(raw))\n",
    "    n = len(raw)\n",
    "    raw = sorted(raw, key=lambda d: map(int, d.split('-')))\n",
    "    no_of_days = 0\n",
    "    no_of_groups = 0\n",
    "    group = 0\n",
    "    total_days = 0\n",
    "    res = []\n",
    "    for i in range(0,n-1):\n",
    "        current_date = datetime.strptime(raw[i], \"%Y-%m-%d\")\n",
    "        current_date_mod = datetime.strftime(current_date, \"%Y-%m-%d\")\n",
    "        con_date = current_date + timedelta(days=1)\n",
    "        con_date_mod = datetime.strftime(con_date, \"%Y-%m-%d\")\n",
    "\n",
    "        next_date = datetime.strptime(raw[i+1], \"%Y-%m-%d\")\n",
    "        next_date_mod = datetime.strftime(next_date, \"%Y-%m-%d\")\n",
    "        if con_date_mod == next_date_mod :\n",
    "            no_of_days += 1\n",
    "            total_days += 1\n",
    "            if no_of_days == 1:\n",
    "                group += 1\n",
    "                no_of_groups = group\n",
    "\n",
    "        else:\n",
    "            no_of_days = 0\n",
    "    return no_of_groups\n",
    "\n",
    "groups = udf(con_groups,StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_base = new_base.withColumn(\"Consective_days\",consecutive_days('date_list'))\n",
    "new_base = new_base.withColumn(\"Consective_groups\",groups('date_list'))\n",
    "new_base = new_base.withColumn(\"avg_con_days\",when((col('Consective_days') != 0)  & (col('Consective_groups') != 0) , round((col('Consective_days')/col('Consective_groups')))).otherwise(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sticker packs sent\n",
    "stickers_sent = active_base.select('user_id_n','sticker_pack_id').groupby('user_id_n').agg(count('sticker_pack_id').alias('sticker_packs_sent'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distinct sticker packs sent \n",
    "stickers_distinct_sent = active_base.select('user_id_n','sticker_pack_id').groupby('user_id_n').agg(countDistinct('sticker_pack_id').alias('distinct_sticker_packs_sent'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in sticker type data\n",
    "Final_stickers_types = sqlContext.read.parquet(\"gs://ds-url-catag/Stickers/stick_bytype/agg_proc_stickertypes/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sticker types used by users\n",
    "data_join = active_base.join(Final_stickers_types,Final_stickers_types.id== active_base.sticker_pack_id).select([active_base.sticker_pack_id,active_base.user_id_n]+[Final_stickers_types.id,Final_stickers_types.type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_join = data_join.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_join.groupby('type').agg(countDistinct('user_id_n')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deriving sticker type variables\n",
    "#paid\n",
    "data_join  = data_join.withColumn(\"is_paid\",when(col('type') == 'PAID',data_join.sticker_pack_id).otherwise(None))\n",
    "data_join  = data_join.withColumn(\"is_free\",when(col('type') == 'FREE',data_join.sticker_pack_id).otherwise(None))\n",
    "data_join  = data_join.withColumn(\"is_subscribed\",when(col('type') == 'SUBSCRIPTION',data_join.sticker_pack_id).otherwise(None))\n",
    "data_join  = data_join.withColumn(\"is_discontinued\",when(col('type') == 'DISCONTINUED',data_join.sticker_pack_id).otherwise(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sticker_types_aggre = data_join.groupby('user_id_n','is_paid','is_free','is_subscribed','is_discontinued').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing strings with numbers for clustering\n",
    "sticker_types_aggre = sticker_types_aggre.withColumn('is_paid',when(col('is_paid').isNull(),0).otherwise(1))\n",
    "sticker_types_aggre = sticker_types_aggre.withColumn('is_free',when(col('is_free').isNull(),0).otherwise(1))\n",
    "sticker_types_aggre = sticker_types_aggre.withColumn('is_subscribed',when(col('is_subscribed').isNull(),0).otherwise(1))\n",
    "sticker_types_aggre = sticker_types_aggre.withColumn('is_discontinued',when(col('is_discontinued').isNull(),0).otherwise(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_stick_base = sticker_types_aggre.groupBy('user_id_n').agg(func.sum('is_paid').alias('sum_paid'),func.sum('is_free').alias('sum_free'),func.sum('is_subscribed').alias('sum_subs'),func.sum('is_discontinued').alias('sum_discont'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join all datasets\n",
    "data_one = distinctdate.join(new_base,new_base.user_id_n == distinctdate.user_id_n).select([distinctdate.user_id_n,distinctdate.numofdays]+[new_base.avg_con_days])\n",
    "data_two = data_one.join(stickers_sent,stickers_sent.user_id_n == data_one.user_id_n).select([data_one.user_id_n,data_one.numofdays,data_one.avg_con_days]+[stickers_sent.sticker_packs_sent])\n",
    "data_three = data_two.join(stickers_distinct_sent,stickers_distinct_sent.user_id_n == data_two.user_id_n).select([data_two.user_id_n,data_two.numofdays,data_two.avg_con_days,data_two.sticker_packs_sent]+[stickers_distinct_sent.distinct_sticker_packs_sent])\n",
    "data_four = data_three.join(more_stick_base,more_stick_base.user_id_n == data_three.user_id_n).select([data_three.user_id_n,data_three.numofdays,data_three.avg_con_days,data_three.sticker_packs_sent,data_three.distinct_sticker_packs_sent]+[more_stick_base.sum_paid,more_stick_base.sum_free,more_stick_base.sum_subs,more_stick_base.sum_discont])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the final file to all the data \n",
    "data_four.dropDuplicates().write.mode('overwrite').parquet(\"gs://ds-url-catag/Stickers/stick_statistics/derived_features/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
