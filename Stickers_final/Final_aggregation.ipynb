{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.parquet(\"gs://ds-url-catag/plenty_stickers_data/event=BBM-STICKER_SPONSORED_LINK-CLICK/pre_final_ds/*.parquet\")\n",
    "Sticker_datasources = ['event=BBM-STICKER-RECEIVED','event=BBM-STICKER-CLICK','event=BBM-STICKER-DOWNLOAD','event=BBM-STICKER-SEND']\n",
    "\n",
    "for ds in Sticker_datasources:\n",
    "    data_read = spark.read.parquet(\"gs://ds-url-catag/plenty_stickers_data/\"+ds+\"/pre_final_ds/*.parquet\")\n",
    "    data = data.union(data_read)\n",
    "new_data = data.dropDuplicates()\n",
    "new_data = new_data.where(col('user_id_n').isNotNull())\n",
    "\n",
    "#processing the Abilty_to_pay column for ease of use\n",
    "new_data = new_data.withColumn('Abilty_to_pay',when(col('Abilty_to_pay') == 'High','2High') \\\n",
    "                               .otherwise(when(col('Abilty_to_pay') == 'Very High','1Very High') \\\n",
    "                               .otherwise(when(col('Abilty_to_pay') == 'Medium','3Medium') \\\n",
    "                               .otherwise(when(col('Abilty_to_pay') == 'low','4low') \\\n",
    "                               .otherwise(when(col('Abilty_to_pay') == 'very low','5very low') \\\n",
    "                               .otherwise(when(col('Abilty_to_pay') == 'NA','6NA')))))))\n",
    "\n",
    "#processing the Free_sticker_usage column for ease of use\n",
    "new_data = new_data.withColumn('Free_sticker_usage',when(col('Free_sticker_usage') == 'High','1High') \\\n",
    "                               .otherwise(when(col('Free_sticker_usage') == 'Medium','2Medium') \\\n",
    "                               .otherwise(when(col('Free_sticker_usage') == 'low','3low') \\\n",
    "                               .otherwise(when(col('Free_sticker_usage') == 'NA','4NA')))))\n",
    "\n",
    "#processing the paid_sticker_usage column for ease of use\n",
    "new_data = new_data.withColumn('paid_sticker_usage',when(col('paid_sticker_usage') == 'High','1High') \\\n",
    "                               .otherwise(when(col('paid_sticker_usage') == 'Medium','2Medium') \\\n",
    "                               .otherwise(when(col('paid_sticker_usage') == 'low','3low') \\\n",
    "                               .otherwise(when(col('paid_sticker_usage') == 'NA','4NA')))))\n",
    "\n",
    "\n",
    "can_pay_list = new_data.groupby(\"user_id_n\").agg(func.collect_list(\"Can_Pay\").alias(\"Can_Pay_list\"))\n",
    "from pyspark.sql.types import StringType\n",
    "def can_pay(raw):\n",
    "        raw = list(set(raw))\n",
    "        n =len(raw)\n",
    "        if \"yes\" in raw:\n",
    "            new_value = \"yes\"\n",
    "        else:\n",
    "            new_value = \"No\"\n",
    "        return new_value\n",
    "can_pay_udf = udf(can_pay,StringType())\n",
    "can_pay_list = can_pay_list.withColumn(\"Can_pay\",can_pay_udf('Can_Pay_list'))\n",
    "\n",
    "Abilty_to_pay_list = new_data.groupby(\"user_id_n\").agg(func.collect_list(\"Abilty_to_pay\").alias(\"Abilty_to_pay_list\"))\n",
    "Free_list = new_data.groupby(\"user_id_n\").agg(func.collect_list(\"Free_sticker_usage\").alias(\"Free_sticker_usage_list\"))\n",
    "paid_list = new_data.groupby(\"user_id_n\").agg(func.collect_list(\"paid_sticker_usage\").alias(\"paid_sticker_usage_list\"))\n",
    "\n",
    "import re\n",
    "def getting_highest_values(raw):\n",
    "    raw = list(set(raw))\n",
    "    raw = sorted(raw)\n",
    "    n =len(raw)\n",
    "    new_value = raw[0]\n",
    "    new_value = re.sub(r'[0-9]','',str(raw[0]))\n",
    "    return new_value\n",
    "get_high_valuesudf = udf(getting_highest_values,StringType())\n",
    "Abilty_to_pay_list = Abilty_to_pay_list.withColumn(\"Ability_to_pay\",get_high_valuesudf('Abilty_to_pay_list'))\n",
    "Free_list = Free_list.withColumn(\"Free_sticker_usage\",get_high_valuesudf('Free_sticker_usage_list'))\n",
    "paid_list = paid_list.withColumn(\"paid_sticker_usage\",get_high_valuesudf('paid_sticker_usage_list'))\n",
    "\n",
    "#joining all the dataframes\n",
    "\n",
    "data_one = can_pay_list.join(Abilty_to_pay_list,Abilty_to_pay_list.user_id_n == can_pay_list.user_id_n,'left').select([can_pay_list.user_id_n,can_pay_list.Can_pay]+[Abilty_to_pay_list.Ability_to_pay])\n",
    "data_two = data_one.join(Free_list,Free_list.user_id_n == Free_list.user_id_n,'left').select([data_one.user_id_n,data_one.Can_pay,data_one.Ability_to_pay]+[Free_list.Free_sticker_usage])\n",
    "data_three = data_two.join(paid_list,paid_list.user_id_n == data_two.user_id_n,'left').select([data_two.user_id_n,data_two.Can_pay,data_two.Ability_to_pay,data_two.Free_sticker_usage]+[paid_list.paid_sticker_usage])\n",
    "final_sticker_data = data_three\n",
    "final_sticker_data.write.mode('overwrite').parquet(OUTPUT_BUCKET+\"Sticker_data/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
