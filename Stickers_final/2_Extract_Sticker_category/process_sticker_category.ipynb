{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "sc.stop()\n",
    "from pyspark.sql import SQLContext\n",
    "sc =SparkContext()\n",
    "sqlContext = SQLContext(sc)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = !gsutil ls gs://ds-url-catag/Stickers/sticker_categories/*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0 \n",
    "remove_quotes = udf(lambda x: re.sub('\"','',x), StringType())\n",
    "remove_slashes = udf(lambda x: re.sub('\\\\\\\\','',x), StringType())\n",
    "for sub_file in files:\n",
    "    sub_str = sub_file.split(\"/\")[6]\n",
    "    extract_string = sub_str[10:]   \n",
    "    category = re.sub(r'[0-9]','',extract_string)\n",
    "    if category != '':\n",
    "        try :\n",
    "            rdd_df = sc.textFile(\"gs://ds-url-catag/Stickers/sticker_categories/*/\"+sub_str+\"/\",use_unicode=False).repartition(sc.defaultParallelism * 3)\n",
    "            df = rdd_df.map(lambda line: line.split(\",\")).map(lambda line: (line[0],line[1],line[2],line[3])).toDF(['Sticker_id','name','animated','Type'])\n",
    "            df = df.withColumn('category',lit(category))\n",
    "            df = df.select(*[remove_quotes(column).alias(column) for column in df.columns])\n",
    "            df = df.select(*[remove_slashes(column).alias(column) for column in df.columns])\n",
    "            print category\n",
    "            print sub_str\n",
    "            df.repartition(1).write.mode('overwrite').parquet(\"gs://ds-url-catag/Stickers/processed_categories/\"+category+\"/\"+sub_str+\"/\")\n",
    "        except ValueError:\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
